{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Short Answer Grading DNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "# Imports and inits\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import collections\n",
    "import re\n",
    "import random\n",
    "import numpy as np\n",
    "import pickle\n",
    "from nltk import sent_tokenize\n",
    "\n",
    "# from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "import keras\n",
    "from keras.preprocessing.text import Tokenizer, text_to_word_sequence\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Sequential, Model, load_model\n",
    "from keras.layers import Dense, LSTM, Dropout, Input, Embedding, Bidirectional\n",
    "from keras.optimizers import RMSprop, Adam\n",
    "from keras import backend as K\n",
    "\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.utils import np_utils\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "N_SEQ = 58\n",
    "N_VOCAB = 20000\n",
    "EMBED_DIM = 300\n",
    "\n",
    "unk_vec = np.zeros(EMBED_DIM)\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "Load STS (semantic text similarity) model trained on SemEval dataset\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "# define pearson correlation as model metric\n",
    "\n",
    "def pearson_corr_neg(a, b):\n",
    "\n",
    "    a_mean = K.mean(a)\n",
    "    b_mean = K.mean(b)\n",
    "    a_diff = a - a_mean\n",
    "    b_diff = b - b_mean\n",
    "\n",
    "    pcorr = K.sum(a_diff*b_diff)/K.sqrt(K.sum(a_diff*a_diff))/K.sqrt(K.sum(b_diff*b_diff))\n",
    "    \n",
    "    return -pcorr\n",
    "\n",
    "fname_model = './models/RNN-sts-max-pc.hdf5'\n",
    "model = load_model(fname_model, custom_objects={'pearson_corr_neg': pearson_corr_neg})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compute_and_print_score(x1_text, x2_text):\n",
    "\n",
    "    x1_sent = sent_tokenize(x1_text)\n",
    "    n_x1_sent = len(x1_sent)\n",
    "\n",
    "    x2_sent = sent_tokenize(x2_text)\n",
    "    n_x2_sent = len(x2_sent)\n",
    "\n",
    "    # copy all previous preprocessing steps here:\n",
    "\n",
    "    # Merge list of sentences\n",
    "    # x1_sent is list of sentence string\n",
    "    # x1_seq is list of list of integer indices\n",
    "\n",
    "    x_sent_all = x1_sent + x2_sent\n",
    "    if len(x_sent_all) == 1:\n",
    "        x_sent_all = x_sent_all + ['the.'] # add dummy sentence so that keras fit_on_texts word_tokenize instead of char_tokenize\n",
    "\n",
    "    # Step 1 : build dict_tmp\n",
    "\n",
    "    # Note : can't set weights for keras embedding layer\n",
    "    # extract dictionary of unique words\n",
    "    Ktokenizer = Tokenizer(num_words=N_VOCAB)\n",
    "    Ktokenizer.fit_on_texts(x_sent_all) \n",
    "    dict_tmp = Ktokenizer.word_index\n",
    "    #print(dict_tmp)\n",
    "    #print(\"----------------------\")\n",
    "\n",
    "    # Step 2 : Load model dictionary into dict_K\n",
    "\n",
    "    def save_obj(obj, name):\n",
    "        with open(name + '.pkl', 'wb') as f:\n",
    "            pickle.dump(obj, f, pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "    def load_obj(name):\n",
    "        with open(name + '.pkl', 'rb') as f:\n",
    "            return pickle.load(f)\n",
    "\n",
    "    dict_K = load_obj('../Proj_Me1/data/dict_K')\n",
    "    #print(\"Length of dict_K :\", len(dict_K))\n",
    "    #print(len(dict_K), list(dict_K.keys())[0:20])\n",
    "\n",
    "\n",
    "    # Step 3 : Extend dict_K with new vocab from dict_tmp\n",
    "\n",
    "    # Note : dictionary assignment assigns pointer not copy content!!!\n",
    "\n",
    "    tmpkeys = list(dict_tmp.keys())\n",
    "    Kkeys = list(dict_K.keys())\n",
    "    i = len(dict_K) + 1\n",
    "    #print(\"New word(s) not in previous dataset model trained on:\")\n",
    "    for w in tmpkeys:\n",
    "        if w not in Kkeys:\n",
    "            #print(w)\n",
    "            dict_K[w] = i\n",
    "            i = i + 1\n",
    "    #print(\"Length of dict_K :\", len(dict_K))\n",
    "    save_obj(dict_K, './data/dict_K+')\n",
    "    Kvals = list(dict_K.values())\n",
    "    Kitems = list(dict_K.items())\n",
    "    #print(Kitems[15347:15350])\n",
    "\n",
    "\n",
    "    # Step 4 : Format text into input for model\n",
    "    sseq_tmp = Ktokenizer.texts_to_sequences(x_sent_all)\n",
    "\n",
    "    # Step 5 : Need to translate word indices derived from dict_tmp \n",
    "    # to indices derived from dict_K\n",
    "    sseq=sseq_tmp\n",
    "    for i,seq_tmp in enumerate(sseq_tmp):\n",
    "        seq=seq_tmp\n",
    "        for j, wj in enumerate(seq_tmp):\n",
    "            # translate dict_tmp index to index in dict_K; \n",
    "            # note that index is one more than the dictionary index, but same as dictionary value\n",
    "            seq[j] = dict_K[tmpkeys[wj-1]]\n",
    "        sseq[i] = seq\n",
    "\n",
    "    # Step 6 : Pad sequences\n",
    "\n",
    "    sseq_pad = pad_sequences(sseq, maxlen=N_SEQ)\n",
    "    #print(len(sseq_pad[0]))\n",
    "\n",
    "    # Step 7 : Make exhaustive pairwise combos\n",
    "\n",
    "    x1 = sseq_pad[:n_x1_sent]\n",
    "    x2 = sseq_pad[n_x1_sent:]\n",
    "    x1_inp = np.zeros((n_x1_sent*n_x2_sent,N_SEQ),dtype=x1.dtype)\n",
    "    x2_inp = np.zeros((n_x1_sent*n_x2_sent,N_SEQ),dtype=x1.dtype)\n",
    "    #print(\"x1:\",type(x1), x1.shape, x1.dtype)\n",
    "    #print(\"x2:\",type(x2), x2.shape, x2.dtype)\n",
    "    #print(\"x1_inp:\",type(x1_inp), x1_inp.shape, x1_inp.dtype)\n",
    "    for i in range(n_x1_sent):\n",
    "        for j in range(n_x2_sent):\n",
    "            n = i*n_x2_sent+j\n",
    "            #print(\"n,i,j:\",n,i,j)\n",
    "            x1_inp[n] = x1[i]\n",
    "            x2_inp[n] = x2[j]\n",
    "\n",
    "    \"\"\"\n",
    "    print(\"x1:\\n\",x1)\n",
    "    print(\"x1_inp:\\n\",x1_inp)\n",
    "\n",
    "    print(\"-------\")\n",
    "    print(\"x2:\\n\",x2)\n",
    "    print(\"x2_inp:\\n\",x2_inp)\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "    # Step 8 : Format input if necessary\n",
    "    # test if it is a single sentence input\n",
    "    # if x1_inp or x2_inp contain single sentence, \n",
    "    # need to reshape x1_inp or x2_inp to expected list of lists input\n",
    "\n",
    "    if isinstance(x1[0], np.int32):\n",
    "        x1_inp = np.reshape(x1_inp,(1,N_SEQ))\n",
    "    if isinstance(x2[0], np.int32):\n",
    "        x2_inp = np.reshape(x2_inp,(1,N_SEQ))\n",
    "\n",
    "\n",
    "\n",
    "    # Step 9 : Compute score\n",
    "\n",
    "    y_pred = model.predict([x1_inp, x2_inp], verbose=0, steps=None)\n",
    "    #print(y_pred)\n",
    "\n",
    "    \"\"\"\n",
    "    Aggregate similarity score is computed assuming first text is \n",
    "    expected correct answer and second is student answer to be graded.\n",
    "\n",
    "    Aggregate similarity score is obtained by :\n",
    "    1. For each sentence in first text (Text1_Sent_i), \n",
    "       take the maximum similarity scores with every sentence\n",
    "       in second text (Text2_Sent_1, Text2_Sent_2 etc) to obtain\n",
    "       \"hits\" in student's answer with respect to expected answer content\n",
    "       in sentence Text1_Sent_i. \n",
    "\n",
    "    2. Sum up normalized scores in step 2 and \n",
    "       divide by number of sentences in first text (model answer text)\n",
    "\n",
    "    \"\"\"\n",
    "    \n",
    "    m = 0.0\n",
    "    for i in range(n_x1_sent):\n",
    "        m += np.max(y_pred[i*n_x2_sent:(i+1)*n_x2_sent])\n",
    "\n",
    "#    print(\"Expected answer :\\n%s\\n\" % x1_text)\n",
    "#    print(\"Student answer  : %s\" % x2_text)\n",
    "    print(\"Aggregate score = %.2f\" % (m/n_x1_sent))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample answers :\n",
      "0 : When the cover was dipped into hot water, the metal cover gained heat from the hot water and expanded. It expanded more than the glass container. Because metal is a better conductor of heat than glass.  This reduced the friction between cover of the jam jar. Thus allowing him to twist the cover off with less force. \n",
      "\n",
      "1 : When the cover was dipped into the basin of hot water, the metal cover gained heat from the hot water. It expanded more than the glass container because metal is a better conductor of heat than glass. This reduced the friction between cover of the jam jar. \n",
      "\n",
      "2 : The metal cover expanded more than the glass container and so he can open the jam jar. \n",
      "\n",
      "3 : The metal cover became lose because of less friction. \n",
      "\n",
      "4 : The hot water made the metal cover expand and so he was able to twist the cover open. \n",
      "\n",
      "Please input an expected answer or choose 1 from above :0\n",
      "Please input a student answer or choose 1 from above :1\n",
      "Aggregate score = 3.47\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Read in input text\n",
    "and sentence_tokenize text into 2 lists of strings: x1_sent and x2_sent\n",
    "followed by merging both lists into x_sent_all\n",
    "\"\"\"\n",
    "sample =[]\n",
    "sample.append('When the cover was dipped into hot water, the metal cover gained heat '\\\n",
    "              'from the hot water and expanded. It expanded more than the glass container. '\\\n",
    "              'Because metal is a better conductor of heat than glass.  This reduced '\\\n",
    "              'the friction between cover of the jam jar. Thus allowing him to twist the '\\\n",
    "              'cover off with less force.')\n",
    "sample.append('When the cover was dipped into the basin of hot water, the metal cover gained '\\\n",
    "              'heat from the hot water. It expanded more than the glass container because '\\\n",
    "              'metal is a better conductor of heat than glass. This reduced the friction '\\\n",
    "              'between cover of the jam jar.')\n",
    "sample.append('The metal cover expanded more than the glass container and so he '\\\n",
    "              'can open the jam jar.')\n",
    "sample.append('The metal cover became lose because of less friction.')\n",
    "sample.append('The hot water made the metal cover expand and so he was able to twist '\\\n",
    "              'the cover open.')\n",
    "\n",
    "print(\"Sample answers :\")\n",
    "for i,s in enumerate(sample):\n",
    "    print(i,\":\", s,'\\n')\n",
    "\n",
    "ans_true = input(\"Please input an expected answer or choose 1 from above :\")\n",
    "if len(ans_true)==1:\n",
    "    ans_true = sample[int(ans_true)]\n",
    "\n",
    "ans = input(\"Please input a student answer or choose 1 from above :\")\n",
    "if len(ans)==1:\n",
    "    ans = sample[int(ans)]\n",
    "\n",
    "\n",
    "compute_and_print_score(ans_true, ans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
